# AI Service Configuration
PORT=5003
NODE_ENV=development

# DeepInfra Configuration (Primary AI Service)
DEEPINFRA_API_KEY=8cb0ACaBs5No54Dvn687iKhE11TPHCr9
DEEPINFRA_BASE_URL=https://api.deepinfra.com/v1/openai
DEEPINFRA_DEFAULT_MODEL=Qwen/QwQ-32B-Preview
DEEPINFRA_FALLBACK_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
DEEPINFRA_MAX_TOKENS=4000
DEEPINFRA_TEMPERATURE=0.7
DEEPINFRA_TIMEOUT=30000

# OpenAI Configuration (Primary)
OPENAI_API_KEY=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
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=2000

# Google Gemini Configuration (Primary)
GOOGLE_AI_API_KEY=AIzaSyCr2nGfVnEiNXugGWeFYP3gXtREk2jkcTs
GOOGLE_MODEL=gemini-2.0-flash-exp

# Anthropic Claude Configuration (Fallback)
ANTHROPIC_API_KEY=your_anthropic_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Cohere Configuration (Fallback)
COHERE_API_KEY=your_cohere_key_here
COHERE_MODEL=command-light

# Rate Limiting
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100
RATE_LIMIT_TOKENS_PER_MINUTE=100000

# Caching Configuration
CACHE_TTL_SECONDS=3600
CACHE_MAX_KEYS=1000

# Monitoring
LOG_LEVEL=info
METRICS_ENABLED=true

# Service Discovery
SERVICE_NAME=ai-service
SERVICE_VERSION=1.0.0
HEALTH_CHECK_INTERVAL=30000

# Cost Optimization
COST_OPTIMIZATION_ENABLED=true
DAILY_TOKEN_LIMIT=1000000
COST_THRESHOLD_USD=10.00